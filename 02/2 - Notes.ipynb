{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2. Accessing Text Corpora and Lexical Resources](https://www.nltk.org/book/ch02.html)\n",
    "\n",
    "Run the cell below before running any other code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Accessing Text Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Guterberg Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "type(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(emma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* notice that emma is a `nltk.corpus.reader.util.StreamBackedCorpusView` object\n",
    "* in order to use the `.concordance` method on the `emma` text, we need to convert `emma` into a `nltk.text.Text` object, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
    "type(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma.concordance(\"surprize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macbeth Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_sentences[1116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_len = max(len(s) for s in macbeth_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in macbeth_sentences if len(s) == longest_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Web and Chat Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext\n",
    "\n",
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:65], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import nps_chat\n",
    "\n",
    "chatroom = nps_chat.posts('10-19-20s_706posts.xml')\n",
    "chatroom[123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.words(fileids=['cg22'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.sents(categories=['news', 'editorial', 'reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stylistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_text = brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(w.lower() for w in news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in modals:\n",
    "    print(m + ':', fdist[m], end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn:** Choose a different section of the Brown Corpus, and adapt the previous example to count a selection of wh words, such as what, when, where, who, and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CFD Sneak Peek\n",
    "\n",
    "* CFD's will be explained in more detail in Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (genre, word)\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories=genre))\n",
    "\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Reuters Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.categories('training/9865')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.categories(['training/9865', 'training/9880'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.fileids('barley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.fileids(['barley', 'corn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - Inaugural Address Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fileid[:4] for fileid in inaugural.fileids()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to how this graph varies from the graph displayed in the book. NLTK's Inaugral Address Corpus is still updated, so data from United States presidents past 2005 are included in this graph.\n",
    "\n",
    "* **note:** for this solution, I used matplotlib library functions to change the size of the graph\n",
    "    * learn more about matplotlib here: [Intro to pyplot Tutorial](https://matplotlib.org/3.3.1/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py)\n",
    "* CFD's will be explained in more detail in Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (target, fileid[:4])\n",
    "    for fileid in inaugural.fileids()\n",
    "    for w in inaugural.words(fileid)\n",
    "    for target in ['america', 'citizen']\n",
    "    if w.lower().startswith(target))\n",
    "\n",
    "plt.figure(figsize=(16, 6)) \n",
    "\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 - Corpora in Other Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.cess_esp.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.floresta.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.indian.words('hindi.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nltk.corpus.udhr.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.udhr.words('Javanese-Latin1')[11:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **note:** for this solution, I used matplotlib library functions to change the size of the graph\n",
    "    * learn more about matplotlib here: [Intro to pyplot Tutorial](https://matplotlib.org/3.3.1/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py)\n",
    "* CFD's will be explained in more detail in Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import udhr\n",
    "\n",
    "languages = ['Chickasaw', 'English', 'German_Deutsch', 'Greenlandic_Inuktikut', 'Hungarian_Magyar', 'Ibibio_Efik']\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (lang, len(word))\n",
    "    for lang in languages\n",
    "    for word in udhr.words(lang + '-Latin1'))\n",
    "\n",
    "plt.figure(figsize=(10, 6)) \n",
    "\n",
    "cfd.plot(cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn:** Pick a language of interest in `udhr.fileids()`, and define a variable `raw_text = udhr.raw(Language-Latin1)`. Now plot a frequency distribution of the letters of the text using `nltk.FreqDist(raw_text).plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 - Text Corpus Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Adventures of B'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "raw = gutenberg.raw(\"burgess-busterbrown.txt\")\n",
    "\n",
    "raw[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = gutenberg.words(\"burgess-busterbrown.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Adventures',\n",
       " 'of',\n",
       " 'Buster',\n",
       " 'Bear',\n",
       " 'by',\n",
       " 'Thornton',\n",
       " 'W',\n",
       " '.',\n",
       " 'Burgess',\n",
       " '1920',\n",
       " ']',\n",
       " 'I',\n",
       " 'BUSTER',\n",
       " 'BEAR',\n",
       " 'GOES',\n",
       " 'FISHING',\n",
       " 'Buster',\n",
       " 'Bear']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = gutenberg.sents(\"burgess-busterbrown.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I'],\n",
       " ['BUSTER', 'BEAR', 'GOES', 'FISHING'],\n",
       " ['Buster',\n",
       "  'Bear',\n",
       "  'yawned',\n",
       "  'as',\n",
       "  'he',\n",
       "  'lay',\n",
       "  'on',\n",
       "  'his',\n",
       "  'comfortable',\n",
       "  'bed',\n",
       "  'of',\n",
       "  'leaves',\n",
       "  'and',\n",
       "  'watched',\n",
       "  'the',\n",
       "  'first',\n",
       "  'early',\n",
       "  'morning',\n",
       "  'sunbeams',\n",
       "  'creeping',\n",
       "  'through',\n",
       "  'the',\n",
       "  'Green',\n",
       "  'Forest',\n",
       "  'to',\n",
       "  'chase',\n",
       "  'out',\n",
       "  'the',\n",
       "  'Black',\n",
       "  'Shadows',\n",
       "  '.'],\n",
       " ['Once',\n",
       "  'more',\n",
       "  'he',\n",
       "  'yawned',\n",
       "  ',',\n",
       "  'and',\n",
       "  'slowly',\n",
       "  'got',\n",
       "  'to',\n",
       "  'his',\n",
       "  'feet',\n",
       "  'and',\n",
       "  'shook',\n",
       "  'himself',\n",
       "  '.'],\n",
       " ['Then',\n",
       "  'he',\n",
       "  'walked',\n",
       "  'over',\n",
       "  'to',\n",
       "  'a',\n",
       "  'big',\n",
       "  'pine',\n",
       "  '-',\n",
       "  'tree',\n",
       "  ',',\n",
       "  'stood',\n",
       "  'up',\n",
       "  'on',\n",
       "  'his',\n",
       "  'hind',\n",
       "  'legs',\n",
       "  ',',\n",
       "  'reached',\n",
       "  'as',\n",
       "  'high',\n",
       "  'up',\n",
       "  'on',\n",
       "  'the',\n",
       "  'trunk',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'as',\n",
       "  'he',\n",
       "  'could',\n",
       "  ',',\n",
       "  'and',\n",
       "  'scratched',\n",
       "  'the',\n",
       "  'bark',\n",
       "  'with',\n",
       "  'his',\n",
       "  'great',\n",
       "  'claws',\n",
       "  '.'],\n",
       " ['After',\n",
       "  'that',\n",
       "  'he',\n",
       "  'yawned',\n",
       "  'until',\n",
       "  'it',\n",
       "  'seemed',\n",
       "  'as',\n",
       "  'if',\n",
       "  'his',\n",
       "  'jaws',\n",
       "  'would',\n",
       "  'crack',\n",
       "  ',',\n",
       "  'and',\n",
       "  'then',\n",
       "  'sat',\n",
       "  'down',\n",
       "  'to',\n",
       "  'think',\n",
       "  'what',\n",
       "  'he',\n",
       "  'wanted',\n",
       "  'for',\n",
       "  'breakfast',\n",
       "  '.'],\n",
       " ['While',\n",
       "  'he',\n",
       "  'sat',\n",
       "  'there',\n",
       "  ',',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'make',\n",
       "  'up',\n",
       "  'his',\n",
       "  'mind',\n",
       "  'what',\n",
       "  'would',\n",
       "  'taste',\n",
       "  'best',\n",
       "  ',',\n",
       "  'he',\n",
       "  'was',\n",
       "  'listening',\n",
       "  'to',\n",
       "  'the',\n",
       "  'sounds',\n",
       "  'that',\n",
       "  'told',\n",
       "  'of',\n",
       "  'the',\n",
       "  'waking',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'little',\n",
       "  'people',\n",
       "  'who',\n",
       "  'live',\n",
       "  'in',\n",
       "  'the',\n",
       "  'Green',\n",
       "  'Forest',\n",
       "  '.'],\n",
       " ['He',\n",
       "  'heard',\n",
       "  'Sammy',\n",
       "  'Jay',\n",
       "  'way',\n",
       "  'off',\n",
       "  'in',\n",
       "  'the',\n",
       "  'distance',\n",
       "  'screaming',\n",
       "  ',',\n",
       "  '\"',\n",
       "  'Thief',\n",
       "  '!'],\n",
       " ['Thief', '!\"'],\n",
       " ['and', 'grinned', '.'],\n",
       " ['\"',\n",
       "  'I',\n",
       "  'wonder',\n",
       "  ',\"',\n",
       "  'thought',\n",
       "  'Buster',\n",
       "  ',',\n",
       "  '\"',\n",
       "  'if',\n",
       "  'some',\n",
       "  'one',\n",
       "  'has',\n",
       "  'stolen',\n",
       "  'Sammy',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'breakfast',\n",
       "  ',',\n",
       "  'or',\n",
       "  'if',\n",
       "  'he',\n",
       "  'has',\n",
       "  'stolen',\n",
       "  'the',\n",
       "  'breakfast',\n",
       "  'of',\n",
       "  'some',\n",
       "  'one',\n",
       "  'else',\n",
       "  '.'],\n",
       " ['Probably', 'he', 'is', 'the', 'thief', 'himself', '.\"'],\n",
       " ['He',\n",
       "  'heard',\n",
       "  'Chatterer',\n",
       "  'the',\n",
       "  'Red',\n",
       "  'Squirrel',\n",
       "  'scolding',\n",
       "  'as',\n",
       "  'fast',\n",
       "  'as',\n",
       "  'he',\n",
       "  'could',\n",
       "  'make',\n",
       "  'his',\n",
       "  'tongue',\n",
       "  'go',\n",
       "  'and',\n",
       "  'working',\n",
       "  'himself',\n",
       "  'into',\n",
       "  'a',\n",
       "  'terrible',\n",
       "  'rage',\n",
       "  '.'],\n",
       " ['\"',\n",
       "  'Must',\n",
       "  'be',\n",
       "  'that',\n",
       "  'Chatterer',\n",
       "  'got',\n",
       "  'out',\n",
       "  'of',\n",
       "  'bed',\n",
       "  'the',\n",
       "  'wrong',\n",
       "  'way',\n",
       "  'this',\n",
       "  'morning',\n",
       "  ',\"',\n",
       "  'thought',\n",
       "  'he',\n",
       "  '.'],\n",
       " ['He',\n",
       "  'heard',\n",
       "  'Blacky',\n",
       "  'the',\n",
       "  'Crow',\n",
       "  'cawing',\n",
       "  'at',\n",
       "  'the',\n",
       "  'top',\n",
       "  'of',\n",
       "  'his',\n",
       "  'lungs',\n",
       "  ',',\n",
       "  'and',\n",
       "  'he',\n",
       "  'knew',\n",
       "  'by',\n",
       "  'the',\n",
       "  'sound',\n",
       "  'that',\n",
       "  'Blacky',\n",
       "  'was',\n",
       "  'getting',\n",
       "  'into',\n",
       "  'mischief',\n",
       "  'of',\n",
       "  'some',\n",
       "  'kind',\n",
       "  '.'],\n",
       " ['He',\n",
       "  'heard',\n",
       "  'the',\n",
       "  'sweet',\n",
       "  'voices',\n",
       "  'of',\n",
       "  'happy',\n",
       "  'little',\n",
       "  'singers',\n",
       "  ',',\n",
       "  'and',\n",
       "  'they',\n",
       "  'were',\n",
       "  'good',\n",
       "  'to',\n",
       "  'hear',\n",
       "  '.'],\n",
       " ['But',\n",
       "  'most',\n",
       "  'of',\n",
       "  'all',\n",
       "  'he',\n",
       "  'listened',\n",
       "  'to',\n",
       "  'a',\n",
       "  'merry',\n",
       "  ',',\n",
       "  'low',\n",
       "  ',',\n",
       "  'silvery',\n",
       "  'laugh',\n",
       "  'that',\n",
       "  'never',\n",
       "  'stopped',\n",
       "  'but',\n",
       "  'went',\n",
       "  'on',\n",
       "  'and',\n",
       "  'on',\n",
       "  ',',\n",
       "  'until',\n",
       "  'he',\n",
       "  'just',\n",
       "  'felt',\n",
       "  'as',\n",
       "  'if',\n",
       "  'he',\n",
       "  'must',\n",
       "  'laugh',\n",
       "  'too',\n",
       "  '.'],\n",
       " ['It', 'was', 'the', 'voice', 'of', 'the', 'Laughing', 'Brook', '.'],\n",
       " ['And',\n",
       "  'as',\n",
       "  'Buster',\n",
       "  'listened',\n",
       "  'it',\n",
       "  'suddenly',\n",
       "  'came',\n",
       "  'to',\n",
       "  'him',\n",
       "  'just',\n",
       "  'what',\n",
       "  'he',\n",
       "  'wanted',\n",
       "  'for',\n",
       "  'breakfast',\n",
       "  '.']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 - Loading your own Corpus\n",
    "\n",
    "In this example, we are going to look at the root directory of this reposity. The `..` stands for a **parent directory**, or a folder one level higher in the folder hierarchy. See [Section 1.4 of this Unix Tutorial](http://www.ee.surrey.ac.uk/Teaching/Unix/unix1.html) for an in depth explanation of this.\n",
    "\n",
    "And instead of looking at all of the files that have a `.` in them, we will observe all of the files that end with `.md`. These are markdown files, which are a type of text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02/2 - Work Notes.md', 'README.md', 'afterword.md', 'log.md', 'plan.md']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "corpus_root = '../'\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*.md') \n",
    "wordlists.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#', 'NLTK', '-', 'Book', '-', 'Resource', '*', ...]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlists.words('README.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately the Penn Treebank is [not a free resource](https://catalog.ldc.upenn.edu/LDC99T42). Fortunately there are a lot of [free alternatives to use](https://stackoverflow.com/q/8949517/12578069).\n",
    "\n",
    "* [American National Corpus](http://www.anc.org/data/masc/downloads/data-download/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Conditional Frequency Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "\n",
    "**Your Turn:** Choose a different section of the Brown Corpus, and adapt the previous example to count a selection of wh words, such as what, when, where, who, and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "humor_text = brown.words(categories='humor')\n",
    "humor_fdist = nltk.FreqDist(w.lower() for w in humor_text)\n",
    "wh = ['what', 'when', 'where', 'who', 'why']\n",
    "\n",
    "for w in wh:\n",
    "    print(w + ':', fdist[m], end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7\n",
    "\n",
    "**Your Turn:** Pick a language of interest in `udhr.fileids()`, and define a variable `raw_text = udhr.raw(Language-Latin1)`. Now plot a frequency distribution of the letters of the text using `nltk.FreqDist(raw_text).plot()`.\n",
    "\n",
    "* in this example, I will choose `Portuguese_Portugues-Latin1`\n",
    "* **note:** for this solution, I used matplotlib library functions to change the size of the graph\n",
    "    * learn more about matplotlib here: [Intro to pyplot Tutorial](https://matplotlib.org/3.3.1/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abkhaz-Cyrillic+Abkh',\n",
       " 'Abkhaz-UTF8',\n",
       " 'Achehnese-Latin1',\n",
       " 'Achuar-Shiwiar-Latin1',\n",
       " 'Adja-UTF8',\n",
       " 'Afaan_Oromo_Oromiffa-Latin1',\n",
       " 'Afrikaans-Latin1',\n",
       " 'Aguaruna-Latin1',\n",
       " 'Akuapem_Twi-UTF8',\n",
       " 'Albanian_Shqip-Latin1',\n",
       " 'Amahuaca',\n",
       " 'Amahuaca-Latin1',\n",
       " 'Amarakaeri-Latin1',\n",
       " 'Amuesha-Yanesha-UTF8',\n",
       " 'Arabela-Latin1',\n",
       " 'Arabic_Alarabia-Arabic',\n",
       " 'Asante-UTF8',\n",
       " 'Ashaninca-Latin1',\n",
       " 'Asheninca-Latin1',\n",
       " 'Asturian_Bable-Latin1',\n",
       " 'Aymara-Latin1',\n",
       " 'Balinese-Latin1',\n",
       " 'Bambara-UTF8',\n",
       " 'Baoule-UTF8',\n",
       " 'Basque_Euskara-Latin1',\n",
       " 'Batonu_Bariba-UTF8',\n",
       " 'Belorus_Belaruski-Cyrillic',\n",
       " 'Belorus_Belaruski-UTF8',\n",
       " 'Bemba-Latin1',\n",
       " 'Bengali-UTF8',\n",
       " 'Beti-UTF8',\n",
       " 'Bichelamar-Latin1',\n",
       " 'Bikol_Bicolano-Latin1',\n",
       " 'Bora-Latin1',\n",
       " 'Bosnian_Bosanski-Cyrillic',\n",
       " 'Bosnian_Bosanski-Latin2',\n",
       " 'Bosnian_Bosanski-UTF8',\n",
       " 'Breton-Latin1',\n",
       " 'Bugisnese-Latin1',\n",
       " 'Bulgarian_Balgarski-Cyrillic',\n",
       " 'Bulgarian_Balgarski-UTF8',\n",
       " 'Cakchiquel-Latin1',\n",
       " 'Campa_Pajonalino-Latin1',\n",
       " 'Candoshi-Shapra-Latin1',\n",
       " 'Caquinte-Latin1',\n",
       " 'Cashibo-Cacataibo-Latin1',\n",
       " 'Cashinahua-Latin1',\n",
       " 'Catalan-Latin1',\n",
       " 'Catalan_Catala-Latin1',\n",
       " 'Cebuano-Latin1',\n",
       " 'Chamorro-Latin1',\n",
       " 'Chayahuita-Latin1',\n",
       " 'Chechewa_Nyanja-Latin1',\n",
       " 'Chickasaw-Latin1',\n",
       " 'Chinanteco-Ajitlan-Latin1',\n",
       " 'Chinanteco-UTF8',\n",
       " 'Chinese_Mandarin-GB2312',\n",
       " 'Chuuk_Trukese-Latin1',\n",
       " 'Cokwe-Latin1',\n",
       " 'Corsican-Latin1',\n",
       " 'Croatian_Hrvatski-Latin2',\n",
       " 'Czech-Latin2',\n",
       " 'Czech-UTF8',\n",
       " 'Czech_Cesky-Latin2',\n",
       " 'Czech_Cesky-UTF8',\n",
       " 'Dagaare-UTF8',\n",
       " 'Dagbani-UTF8',\n",
       " 'Dangme-UTF8',\n",
       " 'Danish_Dansk-Latin1',\n",
       " 'Dendi-UTF8',\n",
       " 'Ditammari-UTF8',\n",
       " 'Dutch_Nederlands-Latin1',\n",
       " 'Edo-Latin1',\n",
       " 'English-Latin1',\n",
       " 'Esperanto-UTF8',\n",
       " 'Estonian_Eesti-Latin1',\n",
       " 'Ewe_Eve-UTF8',\n",
       " 'Fante-UTF8',\n",
       " 'Faroese-Latin1',\n",
       " 'Farsi_Persian-UTF8',\n",
       " 'Farsi_Persian-v2-UTF8',\n",
       " 'Fijian-Latin1',\n",
       " 'Filipino_Tagalog-Latin1',\n",
       " 'Finnish_Suomi-Latin1',\n",
       " 'Fon-UTF8',\n",
       " 'French_Francais-Latin1',\n",
       " 'Frisian-Latin1',\n",
       " 'Friulian_Friulano-Latin1',\n",
       " 'Ga-UTF8',\n",
       " 'Gagauz_Gagauzi-UTF8',\n",
       " 'Galician_Galego-Latin1',\n",
       " 'Garifuna_Garifuna-Latin1',\n",
       " 'German_Deutsch-Latin1',\n",
       " 'Gonja-UTF8',\n",
       " 'Greek_Ellinika-Greek',\n",
       " 'Greek_Ellinika-UTF8',\n",
       " 'Greenlandic_Inuktikut-Latin1',\n",
       " 'Guarani-Latin1',\n",
       " 'Guen_Mina-UTF8',\n",
       " 'HaitianCreole_Kreyol-Latin1',\n",
       " 'HaitianCreole_Popular-Latin1',\n",
       " 'Hani-Latin1',\n",
       " 'Hausa_Haoussa-Latin1',\n",
       " 'Hawaiian-UTF8',\n",
       " 'Hebrew_Ivrit-Hebrew',\n",
       " 'Hebrew_Ivrit-UTF8',\n",
       " 'Hiligaynon-Latin1',\n",
       " 'Hindi-UTF8',\n",
       " 'Hindi_web-UTF8',\n",
       " 'Hmong_Miao-Sichuan-Guizhou-Yunnan-Latin1',\n",
       " 'Hmong_Miao-SouthernEast-Guizhou-Latin1',\n",
       " 'Hmong_Miao_Northern-East-Guizhou-Latin1',\n",
       " 'Hrvatski_Croatian-Latin2',\n",
       " 'Huasteco-Latin1',\n",
       " 'Huitoto_Murui-Latin1',\n",
       " 'Hungarian_Magyar-Latin1',\n",
       " 'Hungarian_Magyar-Latin2',\n",
       " 'Hungarian_Magyar-UTF8',\n",
       " 'Ibibio_Efik-Latin1',\n",
       " 'Icelandic_Yslenska-Latin1',\n",
       " 'Ido-Latin1',\n",
       " 'Igbo-UTF8',\n",
       " 'Iloko_Ilocano-Latin1',\n",
       " 'Indonesian-Latin1',\n",
       " 'Interlingua-Latin1',\n",
       " 'Inuktikut_Greenlandic-Latin1',\n",
       " 'IrishGaelic_Gaeilge-Latin1',\n",
       " 'Italian-Latin1',\n",
       " 'Italian_Italiano-Latin1',\n",
       " 'Japanese_Nihongo-EUC',\n",
       " 'Japanese_Nihongo-SJIS',\n",
       " 'Japanese_Nihongo-UTF8',\n",
       " 'Javanese-Latin1',\n",
       " 'Jola-Fogny_Diola-UTF8',\n",
       " 'Kabye-UTF8',\n",
       " 'Kannada-UTF8',\n",
       " 'Kaonde-Latin1',\n",
       " 'Kapampangan-Latin1',\n",
       " 'Kasem-UTF8',\n",
       " 'Kazakh-Cyrillic',\n",
       " 'Kazakh-UTF8',\n",
       " 'Kiche_Quiche-Latin1',\n",
       " 'Kicongo-Latin1',\n",
       " 'Kimbundu_Mbundu-Latin1',\n",
       " 'Kinyamwezi_Nyamwezi-Latin1',\n",
       " 'Kinyarwanda-Latin1',\n",
       " 'Kituba-Latin1',\n",
       " 'Korean_Hankuko-UTF8',\n",
       " 'Kpelewo-UTF8',\n",
       " 'Krio-UTF8',\n",
       " 'Kurdish-UTF8',\n",
       " 'Lamnso_Lam-nso-UTF8',\n",
       " 'Latin_Latina-Latin1',\n",
       " 'Latin_Latina-v2-Latin1',\n",
       " 'Latvian-Latin1',\n",
       " 'Limba-UTF8',\n",
       " 'Lingala-Latin1',\n",
       " 'Lithuanian_Lietuviskai-Baltic',\n",
       " 'Lozi-Latin1',\n",
       " 'Luba-Kasai_Tshiluba-Latin1',\n",
       " 'Luganda_Ganda-Latin1',\n",
       " 'Lunda_Chokwe-lunda-Latin1',\n",
       " 'Luvale-Latin1',\n",
       " 'Luxembourgish_Letzebuergeusch-Latin1',\n",
       " 'Macedonian-UTF8',\n",
       " 'Madurese-Latin1',\n",
       " 'Makonde-Latin1',\n",
       " 'Malagasy-Latin1',\n",
       " 'Malay_BahasaMelayu-Latin1',\n",
       " 'Maltese-UTF8',\n",
       " 'Mam-Latin1',\n",
       " 'Maninka-UTF8',\n",
       " 'Maori-Latin1',\n",
       " 'Mapudungun_Mapuzgun-Latin1',\n",
       " 'Mapudungun_Mapuzgun-UTF8',\n",
       " 'Marshallese-Latin1',\n",
       " 'Matses-Latin1',\n",
       " 'Mayan_Yucateco-Latin1',\n",
       " 'Mazahua_Jnatrjo-UTF8',\n",
       " 'Mazateco-Latin1',\n",
       " 'Mende-UTF8',\n",
       " 'Mikmaq_Micmac-Mikmaq-Latin1',\n",
       " 'Minangkabau-Latin1',\n",
       " 'Miskito_Miskito-Latin1',\n",
       " 'Mixteco-Latin1',\n",
       " 'Mongolian_Khalkha-Cyrillic',\n",
       " 'Mongolian_Khalkha-UTF8',\n",
       " 'Moore_More-UTF8',\n",
       " 'Nahuatl-Latin1',\n",
       " 'Ndebele-Latin1',\n",
       " 'Nepali-UTF8',\n",
       " 'Ngangela_Nyemba-Latin1',\n",
       " 'NigerianPidginEnglish-Latin1',\n",
       " 'Nomatsiguenga-Latin1',\n",
       " 'NorthernSotho_Pedi-Sepedi-Latin1',\n",
       " 'Norwegian-Latin1',\n",
       " 'Norwegian_Norsk-Bokmal-Latin1',\n",
       " 'Norwegian_Norsk-Nynorsk-Latin1',\n",
       " 'Nyanja_Chechewa-Latin1',\n",
       " 'Nyanja_Chinyanja-Latin1',\n",
       " 'Nzema-UTF8',\n",
       " 'OccitanAuvergnat-Latin1',\n",
       " 'OccitanLanguedocien-Latin1',\n",
       " 'Oromiffa_AfaanOromo-Latin1',\n",
       " 'Osetin_Ossetian-UTF8',\n",
       " 'Oshiwambo_Ndonga-Latin1',\n",
       " 'Otomi_Nahnu-Latin1',\n",
       " 'Paez-Latin1',\n",
       " 'Palauan-Latin1',\n",
       " 'Peuhl-UTF8',\n",
       " 'Picard-Latin1',\n",
       " 'Pipil-Latin1',\n",
       " 'Polish-Latin2',\n",
       " 'Polish_Polski-Latin2',\n",
       " 'Ponapean-Latin1',\n",
       " 'Portuguese_Portugues-Latin1',\n",
       " 'Pulaar-UTF8',\n",
       " 'Punjabi_Panjabi-UTF8',\n",
       " 'Purhepecha-UTF8',\n",
       " 'Qechi_Kekchi-Latin1',\n",
       " 'Quechua-Latin1',\n",
       " 'Quichua-Latin1',\n",
       " 'Rarotongan_MaoriCookIslands-Latin1',\n",
       " 'Rhaeto-Romance_Rumantsch-Latin1',\n",
       " 'Romani-Latin1',\n",
       " 'Romani-UTF8',\n",
       " 'Romanian-Latin2',\n",
       " 'Romanian_Romana-Latin2',\n",
       " 'Rukonzo_Konjo-Latin1',\n",
       " 'Rundi_Kirundi-Latin1',\n",
       " 'Runyankore-rukiga_Nkore-kiga-Latin1',\n",
       " 'Russian-Cyrillic',\n",
       " 'Russian-UTF8',\n",
       " 'Russian_Russky-Cyrillic',\n",
       " 'Russian_Russky-UTF8',\n",
       " 'Sami_Lappish-UTF8',\n",
       " 'Sammarinese-Latin1',\n",
       " 'Samoan-Latin1',\n",
       " 'Sango_Sangho-Latin1',\n",
       " 'Sanskrit-UTF8',\n",
       " 'Saraiki-UTF8',\n",
       " 'Sardinian-Latin1',\n",
       " 'ScottishGaelic_GaidhligAlbanach-Latin1',\n",
       " 'Seereer-UTF8',\n",
       " 'Serbian_Srpski-Cyrillic',\n",
       " 'Serbian_Srpski-Latin2',\n",
       " 'Serbian_Srpski-UTF8',\n",
       " 'Sharanahua-Latin1',\n",
       " 'Shipibo-Conibo-Latin1',\n",
       " 'Shona-Latin1',\n",
       " 'Sinhala-UTF8',\n",
       " 'Siswati-Latin1',\n",
       " 'Slovak-Latin2',\n",
       " 'Slovak_Slovencina-Latin2',\n",
       " 'Slovenian_Slovenscina-Latin2',\n",
       " 'SolomonsPidgin_Pijin-Latin1',\n",
       " 'Somali-Latin1',\n",
       " 'Soninke_Soninkanxaane-UTF8',\n",
       " 'Sorbian-Latin2',\n",
       " 'SouthernSotho_Sotho-Sesotho-Sutu-Sesutu-Latin1',\n",
       " 'Spanish-Latin1',\n",
       " 'Spanish_Espanol-Latin1',\n",
       " 'Sukuma-Latin1',\n",
       " 'Sundanese-Latin1',\n",
       " 'Sussu_Soussou-Sosso-Soso-Susu-UTF8',\n",
       " 'Swaheli-Latin1',\n",
       " 'Swahili_Kiswahili-Latin1',\n",
       " 'Swedish_Svenska-Latin1',\n",
       " 'Tahitian-UTF8',\n",
       " 'Tenek_Huasteco-Latin1',\n",
       " 'Tetum-Latin1',\n",
       " 'Themne_Temne-UTF8',\n",
       " 'Tiv-Latin1',\n",
       " 'Toba-UTF8',\n",
       " 'Tojol-abal-Latin1',\n",
       " 'TokPisin-Latin1',\n",
       " 'Tonga-Latin1',\n",
       " 'Tongan_Tonga-Latin1',\n",
       " 'Totonaco-Latin1',\n",
       " 'Trukese_Chuuk-Latin1',\n",
       " 'Turkish_Turkce-Turkish',\n",
       " 'Turkish_Turkce-UTF8',\n",
       " 'Tzeltal-Latin1',\n",
       " 'Tzotzil-Latin1',\n",
       " 'Uighur_Uyghur-Latin1',\n",
       " 'Uighur_Uyghur-UTF8',\n",
       " 'Ukrainian-Cyrillic',\n",
       " 'Ukrainian-UTF8',\n",
       " 'Umbundu-Latin1',\n",
       " 'Urarina-Latin1',\n",
       " 'Uzbek-Latin1',\n",
       " 'Vietnamese-ALRN-UTF8',\n",
       " 'Vietnamese-UTF8',\n",
       " 'Vlach-Latin1',\n",
       " 'Walloon_Wallon-Latin1',\n",
       " 'Wama-UTF8',\n",
       " 'Waray-Latin1',\n",
       " 'Wayuu-Latin1',\n",
       " 'Welsh_Cymraeg-Latin1',\n",
       " 'WesternSotho_Tswana-Setswana-Latin1',\n",
       " 'Wolof-Latin1',\n",
       " 'Xhosa-Latin1',\n",
       " 'Yagua-Latin1',\n",
       " 'Yao-Latin1',\n",
       " 'Yapese-Latin1',\n",
       " 'Yoruba-UTF8',\n",
       " 'Zapoteco-Latin1',\n",
       " 'Zapoteco-SanLucasQuiavini-Latin1',\n",
       " 'Zhuang-Latin1',\n",
       " 'Zulu-Latin1']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import udhr\n",
    "\n",
    "udhr.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = udhr.raw('Portuguese_Portugues-Latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 6)) \n",
    "\n",
    "nltk.FreqDist(raw_text).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import udhr\n",
    "\n",
    "languages = ['Chickasaw', 'English', 'German_Deutsch', 'Greenlandic_Inuktikut', 'Hungarian_Magyar', 'Ibibio_Efik']\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (lang, len(word))\n",
    "    for lang in languages\n",
    "    for word in udhr.words(lang + '-Latin1'))\n",
    "\n",
    "def plot_freq(lang):\n",
    "    max_length = max([len(word) for word in udhr.words(lang + '-Latin1')])\n",
    "    eng_freq_dist = {}\n",
    "\n",
    "    for i in range(max_length + 1):\n",
    "        eng_freq_dist[i] = cfd[lang].freq(i)\n",
    "\n",
    "    ed = pd.Series(eng_freq_dist, name=lang)\n",
    "\n",
    "    ed.cumsum().plot(legend=True, title='Cumulative Distribution of Word Lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    plot_freq(lang)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
