{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4. Processing Raw Text](https://www.nltk.org/book/ch04.html) - Exercise Solutions\n",
    "\n",
    "* [NLTK-Book-Resource Repository](https://github.com/BetoBob/NLTK-Book-Resource)\n",
    "* [NLTK-Book-Resource Table of Contents](https://github.com/BetoBob/NLTK-Book-Resource#table-of-contents)\n",
    "\n",
    "___\n",
    "\n",
    "**Removed Questions**\n",
    "\n",
    "* 5 `cmp` is no longer a built-in for python-3.0 \n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "Run the cell below before running any other code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "☼ Identify three operations that can be performed on both tuples and lists. Identify three list operations that cannot be performed on tuples. Name a context where using a list instead of a tuple generates a Python error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "☼ Find out how to create a tuple consisting of a single item. There are at least two ways to do this.\n",
    "\n",
    "* [Tuple Syntax](https://wiki.python.org/moin/TupleSyntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = (1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = 1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "☼ Create a list `words = ['is', 'NLP', 'fun', '?']`. Use a series of assignment statements (e.g. `words[1] = words[2]`) and a temporary variable `tmp` to transform this list into the list `['NLP', 'is', 'fun', '!']`. Now do the same transformation using tuple assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "* [Article on Tuple Assignment](https://openbookproject.net/thinkcs/python/english3e/tuples.html#tuple-assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'fun', '!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['is', 'NLP', 'fun', '?']\n",
    "\n",
    "tmp = words[0]\n",
    "words[0] = words[1]\n",
    "words[1] = tmp\n",
    "words[-1] = '!'\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuple assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'fun', '!']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['is', 'NLP', 'fun', '?']\n",
    "\n",
    "(words[0], words[1]) = (words[1], words[0])\n",
    "words[-1] = '!'\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "\n",
    "☼ Does the method for creating a sliding window of n-grams behave correctly for the two limiting cases: `n = 1`, and `n = len(sent)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\n",
    "\n",
    "☼ We pointed out that when empty strings and empty lists occur in the condition part of an `if` clause, they evaluate to `False`. In this case, they are said to be occurring in a Boolean context. Experiment with different kind of non-Boolean expressions in Boolean contexts, and see whether they evaluate as `True` or `False`.\n",
    "\n",
    "### Solution\n",
    "\n",
    "See the documentation on [Python Truth Value Testing](https://docs.python.org/2.4/lib/truth.html) to see all the ways non-Boolean expressions can be evaluated. Some examples of these non-boolean expressions are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class emptyClass:\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = emptyClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.\n",
    "\n",
    "☼ Use the inequality operators to compare strings, e.g. `'Monty' < 'Python'`. What happens when you do `'Z' < 'a'`? Try pairs of strings which have a common prefix, e.g. `'Monty' < 'Montague'`. Read up on \"lexicographical sort\" in order to understand what is going on here. Try comparing structured objects, e.g. `('Monty', 1) < ('Monty', 2)`. Does this behave as expected?\n",
    "\n",
    "### Solution\n",
    "\n",
    "When evaluating the expressions, notice that strings appear to be evaluated in alphabetical order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty' < 'Python'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, it follows ASCII value ordering. Upper case letters `A - Z` are represented by numbers `65 - 90` and lower case letters `a - z` are represented by numbers `97 - 122` in the ASCII table. This makes the order of the words case sensitive.\n",
    "\n",
    "* [ASCII Table](https://www.cs.cmu.edu/~pattis/15-1XX/common/handouts/ascii.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Z' < 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty' < 'Montague'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with non-alphabetical characters like numbers and symbols to see where they are placed in the ASCII table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'01234' < 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'~' < 'a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuple comparisons have interesting behaviors. The first item in each tuple is compared. If they are not equal, then the evaluation of the tuple is made by evaluating the two elements. If the first two elements are equal, then the second item of each tuple is evaluated. This creates a sequence of checks.\n",
    "\n",
    "In the example below, both of the first items in each tuple are equal. Therefore the second items of the tuples are evaluated for the expression. `1 < 2` is a true expression, therefore `('Monty', 1) < ('Monty', 2)` is `true`.\n",
    "\n",
    "* [StackOverflow post on Tuple Comparisons](https://stackoverflow.com/questions/5292303/how-does-tuple-comparison-work-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('Monty', 1) < ('Monty', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.\n",
    "\n",
    "☼ Write code that removes whitespace at the beginning and end of a string, and normalizes whitespace between words to be a single space character.\n",
    "\n",
    "1. do this task using `split()` and `join()`\n",
    "2. do this task using regular expression substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aproach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"   this   is  a string    \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a string'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aproach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "test = \"   this   is  a string    \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a string'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(re.findall('\\w+', test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.\n",
    "\n",
    "☼ Write a program to sort words by length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'are', 'these', 'words', 'couple']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = [\"these\", \"are\", \"a\", \"couple\", \"words\"]\n",
    "\n",
    "def sort_len(list):\n",
    "    return sorted(list, key=len)\n",
    "    \n",
    "sort_len(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.\n",
    "\n",
    "◑ Create a list of words and store it in a variable `sent1`. Now assign `sent2 = sent1`. Modify one of the items in `sent1` and verify that `sent2` has changed.\n",
    "\n",
    "\n",
    "1. Now try the same exercise but instead assign `sent2 = sent1[:]`. Modify `sent1` again and see what happens to `sent2`. Explain.\n",
    "2. Now define `text1` to be a list of lists of strings (e.g. to represent a text consisting of multiple sentences. Now assign `text2 = text1[:]`, assign a new value to one of the words, e.g. `text1[1][1] = 'Monty'`. Check what this did to text2. Explain.\n",
    "3. Load Python's `deepcopy()` function (i.e. from copy `import deepcopy`), consult its documentation, and test that it makes a fresh copy of any object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.\n",
    "\n",
    "◑ Initialize an *n*-by-*m* list of lists of empty strings using list multiplication, e.g. `word_table = [[''] * n] * m`. What happens when you set one of its values, e.g. `word_table[1][2] = \"hello\"`? Explain why this happens. Now write an expression using `range()` to construct a list of lists, and show that it does not have this problem.\n",
    "\n",
    "* **Tip:** use list comprehensions for the second list of lists (with `range`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "* when creating duplicate lists, the same reference will be used\n",
    "* therefore changing one index of a sublist will update the same index in other lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "m = 4\n",
    "\n",
    "word_table = [[''] * n] * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', '', '', '', ''],\n",
       " ['', '', '', '', ''],\n",
       " ['', '', '', '', ''],\n",
       " ['', '', '', '', '']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table[1][2] = \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', '', 'hello', '', ''],\n",
       " ['', '', 'hello', '', ''],\n",
       " ['', '', 'hello', '', ''],\n",
       " ['', '', 'hello', '', '']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### range approach\n",
    "\n",
    "* using list comprehensions and the `range` funciton creates seperate references for each sublist\n",
    "* therefore updating one index of one sublist will not update the same index in other sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table = [['' for i in range(n)] for j in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table[1][2] = 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', '', '', '', ''],\n",
       " ['', '', 'hello', '', ''],\n",
       " ['', '', '', '', ''],\n",
       " ['', '', '', '', '']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.\n",
    "\n",
    "◑ Write code to initialize a two-dimensional array of sets called `word_vowels` and process a list of words, adding each word to `word_vowels[l][v]` where `l` is the length of the word and `v` is the number of vowels it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.\n",
    "\n",
    "◑ Write a function `novel10(text)` that prints any word that appeared in the last 10% of a text that had not been encountered earlier.\n",
    "\n",
    "**Tip:** Python sets are helpful for this kind of exercise.\n",
    "\n",
    "* [Python Sets Documentation](https://docs.python.org/2/library/sets.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Percentage of text can be defined in several ways. Percentage of completetion can be defined more accurately by the amount of characters left in a text. However for this exercise, defining percentage by the amount of words read will make the solution much simpler. Using the `set` object will help when checking the difference between unique words in the first 90% and last 10% of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def novel10(text):\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # standardize words by removing case-sensitivity (all words are lower case)\n",
    "    words_std = [w.lower() for w in words]\n",
    "    \n",
    "    # collect unique words for the first 90% and last 10% of the text\n",
    "    first_90 = set(words_std[:int(len(words_std) * 0.9)]) \n",
    "    last_10 = set(words_std[int(len(words_std) * 0.9):])\n",
    "    \n",
    "    # the difference of the two sets will return the words only found in the last_10\n",
    "    return sorted(list(last_10 - first_90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moby dick will be used as an example text for this function. Notice that one of the unique words for the last 10% of text of 'Moby Dick' is the word 'epilogue'. This makes sense given an epilogue occurs at the end of a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "moby_dick = gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "only_10 = novel10(moby_dick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "781"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(only_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elves',\n",
       " 'enchantment',\n",
       " 'encore',\n",
       " 'enslaved',\n",
       " 'enticing',\n",
       " 'enticings',\n",
       " 'envied',\n",
       " 'epaulets',\n",
       " 'epilogue',\n",
       " 'errand-boy',\n",
       " 'erring',\n",
       " 'etherial',\n",
       " 'europa',\n",
       " 'evanescence',\n",
       " 'evolution',\n",
       " 'evolutions',\n",
       " 'exasperate',\n",
       " 'exclamation-like',\n",
       " 'excludes',\n",
       " 'expectant']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of some of the words\n",
    "\n",
    "only_10[200:220]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.\n",
    "\n",
    "◑ Write a program that takes a sentence expressed as a single string, splits it and counts up the words. Get it to print out each word and the word's frequency, one per line, in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.\n",
    "\n",
    "◑ Read up on Gematria, a method for assigning numbers to words, and for mapping between words having the same number to discover the hidden meaning of texts.\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Gematria\n",
    "\n",
    "1. Write a function `gematria()` that sums the numerical values of the letters of a word, according to the letter values in `letter_vals`:\n",
    "\n",
    "```python\n",
    "letter_vals = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':80, 'g':3, 'h':8,\n",
    "'i':10, 'j':10, 'k':20, 'l':30, 'm':40, 'n':50, 'o':70, 'p':80, 'q':100,\n",
    "'r':200, 's':300, 't':400, 'u':6, 'v':6, 'w':800, 'x':60, 'y':10, 'z':7}\n",
    "```\n",
    "\n",
    "2. Process a corpus (e.g. `nltk.corpus.state_union`) and for each document, count how many of its words have the number 666.\n",
    "\n",
    "3. Write a function `decode()` to process a text, randomly replacing words with their Gematria equivalents, in order to discover the \"hidden meaning\" of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.\n",
    "\n",
    "◑ Write a function `shorten(text, n)` to process a text, omitting the `n` most frequently occurring words of the text. How readable is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "The solution below assumes that all word tokens are seperated by space. You might be able to improve the accuracy of this solutions by removing words from the original text using regular expressions.\n",
    "\n",
    "* you can also improve this solution by removing stop words, or removing punctiation like periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def shorten(text, n):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # standardize words by removing case-sensitivity (all words are lower case)\n",
    "    words_std = [w.lower() for w in words]\n",
    "    \n",
    "    # find most common words (not case sensitive)\n",
    "    n_common = [w for (w, _) in nltk.FreqDist(words_std).most_common(n)]\n",
    "    \n",
    "    return ' '.join([w for w in words if w.lower() not in n_common])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "moby_dick = gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "test = shorten(moby_dick, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[ Moby Dick Herman Melville 1851 ] ETYMOLOGY ( Supplied Late Consumptive Usher Grammar School ) pale Usher threadbare coat heart body brain see ever dusting lexicons grammars queer handkerchief mockingly embellished gay flags known nations world loved dust grammars somehow mildly reminded mortality While take hand school others teach name whale-fish called our tongue leaving through ignorance letter H almost alone maketh signification word deliver true HACKLUYT ... Sw. Dan HVAL animal named roundness rolling Dan HVALT arched vaulted WEBSTER'S DICTIONARY ... immediately Dut Ger WALLEN A.S. WALW-IAN roll wallow RICHARDSON DICTIONARY KETOS GREEK CETUS LATIN WHOEL ANGLO-SAXON HVALT DANISH WAL DUTCH HWAL SWEDISH ICELANDIC ENGLISH BALEINE FRENCH BALLENA SPANISH PEKEE-NUEE-NUEE FEGEE PEKEE-NUEE-NUEE ERROMANGOAN EXTRACTS ( Supplied Sub-Sub-Librarian ) seen mere painstaking burrower grub-worm poor devil Sub-Sub appears gone through Vaticans street-stalls earth picking whatever random allusions \""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.\n",
    "\n",
    "◑ Write code to print out an index for a lexicon, allowing someone to look up words according to their meanings (or pronunciations; whatever properties are contained in lexical entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.\n",
    "\n",
    "◑ Write a list comprehension that sorts a list of WordNet synsets for proximity to a given synset. For example, given the synsets `minke_whale.n.01`, `orca.n.01`, `novel.n.01`, and `tortoise.n.01`, sort them according to their `shortest_path_distance()` from `right_whale.n.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.\n",
    "\n",
    "◑ Write a function that takes a list of words (containing duplicates) and returns a list of words (with no duplicates) sorted by decreasing frequency. E.g. if the input list contained 10 instances of the word 'table' and 9 instances of the word 'chair', then 'table' would appear before 'chair' in the output list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "* [More information on FreqDist / Counter](https://stackoverflow.com/questions/23042699/freqdist-in-nltk-not-sorting-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def sort_common(words):\n",
    "    \n",
    "    # standardize words by removing case-sensitivity (all words are lower case)\n",
    "    words_std = [w.lower() for w in words]\n",
    "    \n",
    "    return [w for (w, _) in Counter(words_std).most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " 'the',\n",
       " '.',\n",
       " 'of',\n",
       " 'and',\n",
       " 'a',\n",
       " 'to',\n",
       " 'in',\n",
       " ';',\n",
       " 'that',\n",
       " \"'\",\n",
       " '-',\n",
       " 'his',\n",
       " 'it',\n",
       " 'i',\n",
       " 'he',\n",
       " 'but',\n",
       " 's',\n",
       " 'as',\n",
       " 'is',\n",
       " 'with',\n",
       " 'was',\n",
       " 'for',\n",
       " 'all',\n",
       " '\"']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "moby_dick = gutenberg.words('melville-moby_dick.txt')\n",
    "\n",
    "sort_common(moby_dick)[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.\n",
    "\n",
    "◑ Write a function that takes a text and a vocabulary as its arguments and returns the set of words that appear in the text but not in the vocabulary. Both arguments can be represented as lists of strings. Can you do this in a single line, using `set.difference()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "This solution can be improved by standardizing the tokenized words and vocab using a list comprehension and the `.lower()` method. This solution is case-sensitive for brevity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# text is a raw string\n",
    "# vocab is a list of words\n",
    "\n",
    "def not_in_vocab(text, vocab):\n",
    "    return set(word_tokenize(text)) - set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'couple', 'here', 'sample', 'text', 'words'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"here is a sample text with a couple of words\"\n",
    "vocab = [\"is\", \"a\", \"with\", \"of\"]\n",
    "\n",
    "not_in_vocab(text, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.\n",
    "\n",
    "◑ Import the `itemgetter()` function from the operator module in Python's standard library (i.e. `from operator import itemgetter`). Create a list words containing several words. Now try calling: `sorted(words, key=itemgetter(1))`, and `sorted(words, key=itemgetter(-1))`. Explain what `itemgetter()` is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "The `itemgetter` function takes an integer as an argument and retrieves the index of a list. In this case, `itemgetter` treats each word as a list of characters. Therefore words are sorted by the character index of the string. Notice that `itemgetter(2)` will not work because \"ai\" is the longest word in the list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"these\", \"are\", \"ai\", \"couple\", \"words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['these', 'are', 'couple', 'ai', 'words']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(words, key=itemgetter(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'ai', 'couple', 'these', 'words']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(words, key=itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['these', 'ai', 'couple', 'words', 'are']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(words, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-184-c8211b71107e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "sorted(words, key=itemgetter(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23.\n",
    "\n",
    "◑ Write a recursive function `lookup(trie, key)` that looks up a key in a trie, and returns the value it finds. Extend the function to return a word when it is uniquely determined by its prefix (e.g. 'vanguard' is the only word that starts with vang-, so `lookup(trie, 'vang')` should return the same thing as `lookup(trie, 'vanguard')`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.\n",
    "\n",
    "◑ Read up on \"keyword linkage\" (chapter 5 of (Scott & Tribble, 2006)). Extract keywords from NLTK's Shakespeare Corpus and using the NetworkX package, plot keyword linkage networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25.\n",
    "\n",
    "◑ Read about string edit distance and the Levenshtein Algorithm. Try the implementation provided in `nltk.edit_distance()`. In what way is this using dynamic programming? Does it use the bottom-up or top-down approach? \n",
    "\n",
    "* http://norvig.com/spell-correct.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26.\n",
    "\n",
    "◑ The Catalan numbers arise in many applications of combinatorial mathematics, including the counting of parse trees ([6](https://www.nltk.org/book/ch08.html#sec-grammar-development)). The series can be defined as follows: `C0 = 1`, and `Cn+1 = Σ0..n (CiCn-i)`.\n",
    "\n",
    "1. Write a recursive function to compute nth Catalan number Cn.\n",
    "2. Now write another function that does this computation using dynamic programming.\n",
    "3. Use the timeit module to compare the performance of these functions as n increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.\n",
    "\n",
    "★ Reproduce some of the results of (Zhao & Zobel, 2007) concerning authorship identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28.\n",
    "\n",
    "★ Study gender-specific lexical choice, and see if you can reproduce some of the results of http://www.clintoneast.com/articles/words.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29.\n",
    "\n",
    "★ Write a recursive function that pretty prints a trie in alphabetically sorted order, e.g.:\n",
    "\n",
    "```\n",
    "chair: 'flesh'\n",
    "---t: 'cat'\n",
    "--ic: 'stylish'\n",
    "---en: 'dog'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30.\n",
    "\n",
    "★ With the help of the trie data structure, write a recursive function that processes text, locating the uniqueness point in each word, and discarding the remainder of each word. How much compression does this give? How readable is the resulting text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 31. \n",
    "\n",
    "★ Obtain some raw text, in the form of a single, long string. Use Python's `textwrap` module to break it up into multiple lines. Now write code to add extra spaces between words, in order to justify the output. Each line must have the same width, and spaces must be approximately evenly distributed across each line. No line can begin or end with a space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32.\n",
    "\n",
    "★ Develop a simple extractive summarization tool, that prints the sentences of a document which contain the highest total word frequency. Use `FreqDist()` to count word frequencies, and use `sum` to sum the frequencies of the words in each sentence. Rank the sentences according to their score. Finally, print the n highest-scoring sentences in document order. Carefully review the design of your program, especially your approach to this double sorting. Make sure the program is written as clearly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 33.\n",
    "\n",
    "★ Read the following article on semantic orientation of adjectives. Use the NetworkX package to visualize a network of adjectives with edges to indicate same vs different semantic orientation. \n",
    "\n",
    "* http://www.aclweb.org/anthology/P97-1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 34.\n",
    "\n",
    "★ Design an algorithm to find the \"statistically improbable phrases\" of a document collection.\n",
    "\n",
    "* http://www.amazon.com/gp/search-inside/sipshelp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 35.\n",
    "\n",
    "★ Write a program to implement a brute-force algorithm for discovering word squares, a kind of `n × n` crossword in which the entry in the nth row is the same as the entry in the nth column. For discussion, see http://itre.cis.upenn.edu/~myl/languagelog/archives/002679.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
